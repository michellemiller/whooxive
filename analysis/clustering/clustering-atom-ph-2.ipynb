{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Can I predict the existence of subfields with some cool unsupervised learning algorithm? \n",
    "\n",
    "For starters, let's just use regular n-grams. A more advanced version would be to look for noun phrases or J&K POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Need to add parent directoy to sys.path to find 'metadataDB'\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "%matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "# import scipy as sp\n",
    "import re\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# Natural language processing toolkit\n",
    "# To use this, run nltk.download() and download 'stopwords'\n",
    "# from nltk.corpus import stopwords\n",
    "# s=stopwords.words('english') + ['']\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import SparsePCA\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# SQL\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from metadataDB.declareDatabase import *\n",
    "from sqlalchemy import or_, and_\n",
    "\n",
    "engine = create_engine(\"sqlite:///../../arXiv_metadata.db\", echo=False)\n",
    "Base.metadata.bind = engine\n",
    "DBsession = sessionmaker(bind=engine)\n",
    "session = DBsession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'acc-phys', u'adap-org', u'alg-geom', u'ao-sci', u'astro-ph', u'astro-ph.CO', u'astro-ph.EP', u'astro-ph.GA', u'astro-ph.HE', u'astro-ph.IM', u'astro-ph.SR', u'atom-ph', u'bayes-an', u'chao-dyn', u'chem-ph', u'comp-gas', u'cond-mat', u'cond-mat.dis-nn', u'cond-mat.mes-hall', u'cond-mat.mtrl-sci', u'cond-mat.other', u'cond-mat.quant-gas', u'cond-mat.soft', u'cond-mat.stat-mech', u'cond-mat.str-el', u'cond-mat.supr-con', u'cs.AI', u'cs.AR', u'cs.CC', u'cs.CE', u'cs.CG', u'cs.CL', u'cs.CR', u'cs.CV', u'cs.CY', u'cs.DB', u'cs.DC', u'cs.DL', u'cs.DM', u'cs.DS', u'cs.ET', u'cs.FL', u'cs.GL', u'cs.GR', u'cs.GT', u'cs.HC', u'cs.IR', u'cs.IT', u'cs.LG', u'cs.LO', u'cs.MA', u'cs.MM', u'cs.MS', u'cs.NA', u'cs.NE', u'cs.NI', u'cs.OH', u'cs.PF', u'cs.PL', u'cs.RO', u'cs.SC', u'cs.SD', u'cs.SE', u'cs.SI', u'cs.SY', u'dg-ga', u'funct-an', u'gr-qc', u'hep-ex', u'hep-lat', u'hep-ph', u'hep-th', u'math-ph', u'math.AC', u'math.AG', u'math.AP', u'math.AT', u'math.CA', u'math.CO', u'math.CT', u'math.CV', u'math.DG', u'math.DS', u'math.FA', u'math.GM', u'math.GN', u'math.GR', u'math.GT', u'math.HO', u'math.IT', u'math.KT', u'math.LO', u'math.MG', u'math.MP', u'math.NA', u'math.NT', u'math.OA', u'math.OC', u'math.PR', u'math.QA', u'math.RA', u'math.RT', u'math.SG', u'math.SP', u'math.ST', u'mtrl-th', u'nlin.AO', u'nlin.CD', u'nlin.CG', u'nlin.PS', u'nlin.SI', u'nucl-ex', u'nucl-th', u'patt-sol', u'physics.acc-ph', u'physics.ao-ph', u'physics.atm-clus', u'physics.atom-ph', u'physics.bio-ph', u'physics.chem-ph', u'physics.class-ph', u'physics.comp-ph', u'physics.data-an', u'physics.ed-ph', u'physics.flu-dyn', u'physics.gen-ph', u'physics.geo-ph', u'physics.hist-ph', u'physics.ins-det', u'physics.med-ph', u'physics.optics', u'physics.plasm-ph', u'physics.pop-ph', u'physics.soc-ph', u'physics.space-ph', u'plasm-ph', u'q-alg', u'q-bio', u'q-bio.BM', u'q-bio.CB', u'q-bio.GN', u'q-bio.MN', u'q-bio.NC', u'q-bio.OT', u'q-bio.PE', u'q-bio.QM', u'q-bio.SC', u'q-bio.TO', u'q-fin.CP', u'q-fin.EC', u'q-fin.GN', u'q-fin.MF', u'q-fin.PM', u'q-fin.PR', u'q-fin.RM', u'q-fin.ST', u'q-fin.TR', u'quant-ph', u'solv-int', u'stat.AP', u'stat.CO', u'stat.ME', u'stat.ML', u'stat.OT', u'stat.TH', u'supr-con']\n"
     ]
    }
   ],
   "source": [
    "# What are the available categories?\n",
    "categories = sorted([x.name for x in session.query(Category)])\n",
    "print categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.7947340012\n"
     ]
    }
   ],
   "source": [
    "abstract_all_tmp = {'category': [], 'abstract': []}\n",
    "# category_list = sorted(['atom-ph', 'quant-ph', 'optics', 'nlin', 'str-el', 'stat'])\n",
    "category_list = sorted(['atom-ph'])\n",
    "category_len = len(category_list)\n",
    "\n",
    "start = time.time()\n",
    "for item in category_list:\n",
    "    query = session.query(Article_Category)\\\n",
    "                        .join(Category)\\\n",
    "                        .join(Article)\\\n",
    "                        .filter(Category.name.like('%' + item + '%'))\n",
    "#     query = session.query(Article_Category)\\\n",
    "#                         .join(Category)\\\n",
    "#                         .join(Article)\\\n",
    "#                         .filter(Category.name.like('%' + item + '%'))\n",
    "    result = [' '.join(x.article.abstract.split()) for x in query]\n",
    "    abstract_all_tmp['abstract'].extend(result)\n",
    "    abstract_all_tmp['category'].extend([item]*len(result))\n",
    "print time.time() - start\n",
    "# for item in query:\n",
    "#     abstract_all['category'].append(item.category.name)\n",
    "#     abstract_all['abstract'].append(' '.join(item.article.abstract.split()))\n",
    "# print time.time() - start\n",
    "# abstract_all['atom-ph'] = [x.article.abstract for x in query.all()]\n",
    "# session.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atom-ph        9156\n",
      "Total          9156\n"
     ]
    }
   ],
   "source": [
    "# Breakdown of categories?\n",
    "count = Counter(abstract_all_tmp['category'])\n",
    "for key, val in count.iteritems():\n",
    "    print '{:<15}{}'.format(key, val)\n",
    "print '{:<15}{}'.format('Total', len(abstract_all_tmp['abstract']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract_all = abstract_all_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ##Oops! How many overlapping articles do we have? I forgot that arXiv categories aren't unique.\n",
    "# # Let's remove all duplicates.\n",
    "# # This is slow but I am tired.\n",
    "\n",
    "# counter_duplicate = Counter(abstract_all_tmp['abstract'])\n",
    "\n",
    "# abstract_all = {'category': [], 'abstract': []}\n",
    "# for cat, abstract in itertools.izip(abstract_all_tmp['category'], abstract_all_tmp['abstract']):\n",
    "#     if counter_duplicate[abstract] == 1:\n",
    "#         abstract_all['category'].append(cat)\n",
    "#         abstract_all['abstract'].append(abstract)\n",
    "# print len(abstract_all['category'])\n",
    "# print len(abstract_all['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Breakdown of categories? That's a lot of repetition!!!\n",
    "# count = Counter(abstract_all['category'])\n",
    "# for key, val in count.iteritems():\n",
    "#     print '{:<15}{}'.format(key, val)\n",
    "# print '{:<15}{}'.format('Total', len(abstract_all['abstract']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train on 90% of the data. Random_state ensures that we always get the same result.\n",
    "x_train, x_test, y_train, y_test = train_test_split(abstract_all['abstract'],\n",
    "                                                    abstract_all['category'],\n",
    "                                                    random_state=42,\n",
    "                                                    train_size=0.9)\n",
    "\n",
    "counter_train = Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I lied, I'm starting with supervised learning (as a comparison). We're looking at ~60-70% accuracy for these cateogories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #SVC(kernel='linear') is good\n",
    "# clf_supervised = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "#                            ('tfidf', TfidfTransformer()),\n",
    "# #                            ('clf', LinearSVC())])\n",
    "#                            ('clf', LinearSVC(C=1,penalty='l1',dual=False,))])\n",
    "# start = time.time()\n",
    "# clf_supervised.fit(x_train, y_train)\n",
    "# print time.time() - start\n",
    "\n",
    "# start = time.time()\n",
    "# predict = clf_supervised.predict(x_test)\n",
    "# print time.time() - start\n",
    "# #print text_abstract_clf.predict(train_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, predict))\n",
    "# print('Accuracy score: %0.2f' % accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the most important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Most important chunks. See http://scikit-learn.org/stable/auto_examples/text/document_clustering.html\n",
    "# most_important_words = clf_supervised.named_steps['clf'].coef_.argsort()[:, ::-1]\n",
    "\n",
    "# terms =  clf_supervised.named_steps['vect'].get_feature_names()\n",
    "# for i in range(len(category_list)):\n",
    "#     print \"Category %s:\" % (category_list[i])\n",
    "#     print ', '.join([terms[x] for x in most_important_words[i, :20]])\n",
    "#     print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try KMeans clustering. \n",
    "See: http://scikit-learn.org/stable/auto_examples/text/document_clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620.14134407\n",
      "4.18002891541\n"
     ]
    }
   ],
   "source": [
    "# 20 is good\n",
    "# n_clusters = 20\n",
    "n_clusters = 20\n",
    "# Reduce n_init to 10 for testing purposes.\n",
    "clf_unsupervised = Pipeline([('vect', CountVectorizer(ngram_range=(1,3), stop_words='english')),\n",
    "                             ('tfidf', TfidfTransformer()),\n",
    "                             ('clf', KMeans(n_clusters=n_clusters, n_init=20))])\n",
    "start = time.time()\n",
    "clf_unsupervised.fit(x_train)\n",
    "print time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "predict_train = clf_unsupervised.predict(x_train)\n",
    "predict = clf_unsupervised.predict(x_test)\n",
    "print time.time() - start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model and predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0559208393\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "joblib.dump(clf_unsupervised, 'cluster-atom-ph-2.pkl', compress=3) \n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Which clusters most closely align with which the original categories?\n",
    "# # Find the strongest correlation, and assign that cluster to the category. Iterate.\n",
    "# # matrix_train = [[sum((a==cat and b==x for a,b in zip(y_train, predict_train)))\n",
    "# #                    for x in range(0,n_clusters)] \n",
    "# #                    for cat in category_list]\n",
    "\n",
    "\n",
    "# counter_category = Counter(y_train)\n",
    "# counter_cluster = Counter(predict_train)\n",
    "# accuracy_train_initial = np.array(\n",
    "# #     [[sum((a==cat and b==x for a,b in zip(y_train, predict_train)))*1./counter_cluster[x]\n",
    "#     [[sum((a==cat and b==x for a,b in zip(y_train, predict_train)))*1./counter_category[cat]\n",
    "#            for x in range(0,n_clusters)] \n",
    "#            for cat in category_list])\n",
    "# clusterToCategory = dict()\n",
    "# # categoryToCluster = dict()\n",
    "\n",
    "# for cluster, item in enumerate(np.argmax(accuracy_train_initial, axis=0).tolist()):\n",
    "#     clusterToCategory[cluster] = category_list[item]\n",
    "\n",
    "\n",
    "# # category_list_remaining = list(category_list)\n",
    "# # cluster_list_remaining = range(0, n_clusters)\n",
    "# # for x in range(0, len(category_list)):\n",
    "# #     accuracy_train = np.array(\n",
    "# #                         [[sum((a==cat and b==x for a,b in zip(y_train, predict_train)))*1./counter_cluster[x]\n",
    "# #                            for x in cluster_list_remaining] \n",
    "# #                            for cat in category_list_remaining])\n",
    "\n",
    "    \n",
    "# #     # Find largest value in the category axis\n",
    "# #     cat_ind, cluster_ind = np.unravel_index(np.argmax(accuracy_train), accuracy_train.shape)\n",
    "# #     clusterToCategory[cluster_list_remaining[cluster_ind]] = category_list_remaining[cat_ind]\n",
    "# #     categoryToCluster[category_list_remaining[cat_ind]] = cluster_list_remaining[cluster_ind]\n",
    "    \n",
    "# #     # Remove those entries from the lists.\n",
    "# #     category_list_remaining.remove(category_list_remaining[cat_ind])\n",
    "# #     cluster_list_remaining.remove(cluster_list_remaining[cluster_ind])\n",
    "# # #     break\n",
    "\n",
    "# # # The remaining clusters predict empty strings\n",
    "# # for item in cluster_list_remaining:\n",
    "# #     clusterToCategory[item] = ''\n",
    "# # clusterToCategory_list = sorted(clusterToCategory.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # The table is normalized by number of elements in each cluster.\n",
    "# print 'Training data'\n",
    "# print ('{:<10}' + '{:<10}'  *n_clusters).format('', *range(0, n_clusters))\n",
    "# print ('{:<10}' + '{:<10}'  *n_clusters).format('', *[clusterToCategory[x] for x in range(0, n_clusters)])\n",
    "# for cat, item in zip(category_list, accuracy_train_initial):\n",
    "#     print ('{:<10}' + '{:<10.2}'*n_clusters).format(cat, *item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Is there overlap between the clusters and existing categories ('ground truth')?\n",
    "# matrix = [[sum((a==cat and b==x for a,b in zip(y_test, predict)))\n",
    "#            for x in range(0,n_clusters)] \n",
    "#            for cat in category_list]\n",
    "\n",
    "# print 'Test data'\n",
    "# print ('{:<10}' + '{:<10}'  *n_clusters).format('', *range(0, n_clusters))\n",
    "# print ('{:<10}' + '{:<10}'  *n_clusters).format('', *[clusterToCategory[x] for x in range(0, n_clusters)])\n",
    "# for cat, item in zip(category_list, matrix):\n",
    "#     print ('{:<10}' + '{:<10}'*n_clusters).format(cat, *item)\n",
    "    \n",
    "    \n",
    "# # # Oops, this is the same as the confusion matrix?\n",
    "# # tmp_reverse_category = dict([(y,x) for x,y in enumerate(category_list)])\n",
    "# # y_test_num = [tmp_reverse_category[x] for x in y_test]\n",
    "# # print ''\n",
    "# # print 'Confusion matrix:'\n",
    "# # print confusion_matrix(y_test_num, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # We can now make a prediction based on these categories.\n",
    "# predict_category = [clusterToCategory[y] for y in predict]\n",
    "\n",
    "# print(classification_report(y_test, predict_category))\n",
    "# print('Accuracy score: %0.2f' % accuracy_score(y_test, predict_category))\n",
    "# print confusion_matrix(y_test, predict_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "recombination, rate, ion, dr, 2p, 2s, electron, storage, ions, storage ring, ring, rate coefficients, recombination rate, coefficients, fe, heavy, data, rate coefficient, heavy ion, 2s 2p\n",
      "\n",
      "Cluster 1:\n",
      "scattering, cross, section, cross section, resonances, scattering length, length, body, energy, wave, range, resonance, efimov, atoms, elastic, atom, universal, ultracold, feshbach, electron\n",
      "\n",
      "Cluster 2:\n",
      "rydberg, atoms, dipole, states, interactions, rydberg atoms, interaction, van der, der, waals, van der waals, der waals, van, atom, excitation, rydberg states, state, blockade, dipole dipole, range\n",
      "\n",
      "Cluster 3:\n",
      "atom, atomic, electron, atoms, laser, time, light, pulse, energy, model, experimental, photon, wave, results, using, electrons, phase, al, optical, pulses\n",
      "\n",
      "Cluster 4:\n",
      "ion, ions, trap, levels, transitions, radiative, state, energy, decay, lines, strengths, transition, electron, atomic, rates, calculations, results, ion trap, charged, emission\n",
      "\n",
      "Cluster 5:\n",
      "bose, condensate, einstein, bose einstein, bose einstein condensate, einstein condensate, condensates, bec, gas, fermi, atoms, phase, atom, einstein condensates, bose einstein condensates, quantum, interactions, trap, density, potential\n",
      "\n",
      "Cluster 6:\n",
      "cavity, light, phase, optical, noise, mode, atoms, atomic, atom, laser, field, photon, probe, coupling, single, control, state, frequency, quantum, absorption\n",
      "\n",
      "Cluster 7:\n",
      "corrections, alpha, hyperfine, nuclear, hydrogen, muonic, qed, proton, order, splitting, hyperfine splitting, lamb shift, lamb, shift, correction, results, structure, relativistic, muonic hydrogen, electron\n",
      "\n",
      "Cluster 8:\n",
      "lattice, optical, optical lattice, phases, atoms, lattices, phase, quantum, optical lattices, spin, density, superfluid, dimensional, ultracold, cold, atom, potential, interactions, systems, states\n",
      "\n",
      "Cluster 9:\n",
      "edm, moment, electric, nuclear, electric dipole, dipole, parity, dipole moment, electric dipole moment, electron, odd, violating, moments, violation, spin, pnc, calculations, hyperfine, search, atomic\n",
      "\n",
      "Cluster 10:\n",
      "alpha, variation, fine structure, fine structure constant, fine, structure constant, constant, structure, structure constant alpha, constant alpha, transitions, variation fine structure, variation fine, mu, sensitivity, constants, 10, fundamental constants, transition, fundamental\n",
      "\n",
      "Cluster 11:\n",
      "magnetic, field, magnetic field, spin, atoms, cell, atomic, fields, vapor, frequency, rb, magnetometer, magnetic fields, optical, zeeman, using, resonance, laser, microwave, state\n",
      "\n",
      "Cluster 12:\n",
      "clock, frequency, optical, clocks, shift, 10, transition, lattice, atomic, shifts, uncertainty, clock transition, optical frequency, times, stability, optical lattice, sr, based, times 10, laser\n",
      "\n",
      "Cluster 13:\n",
      "ionization, laser, electron, field, time, harmonic, pulse, strong, pulses, attosecond, hhg, dependent, time dependent, strong field, laser field, high, intense, generation, spectra, energy\n",
      "\n",
      "Cluster 14:\n",
      "frequency, laser, nm, comb, frequency comb, optical, fiber, transition, mhz, diode, locked, spectroscopy, cavity, power, linewidth, lasers, using, stabilized, light, laser frequency\n",
      "\n",
      "Cluster 15:\n",
      "cross, cross sections, sections, ionization, electron, energy, energies, cross section, section, differential, impact, differential cross, collisions, scattering, calculations, collision, total, calculated, ev, ps\n",
      "\n",
      "Cluster 16:\n",
      "molecules, state, electric, states, ground, ground state, field, vibrational, molecular, excited, ultracold, bound, dipole, fields, rotational, levels, electric field, molecule, quantum, atom\n",
      "\n",
      "Cluster 17:\n",
      "quantum, spin, information, quantum information, states, single, state, entanglement, systems, ion, control, atoms, optical, light, atomic, photon, processing, qubit, atom, qubits\n",
      "\n",
      "Cluster 18:\n",
      "cooling, trap, atoms, optical, laser, mot, magneto, laser cooling, optical trap, magneto optical, loading, trapping, trapped, magneto optical trap, beam, dipole trap, temperature, ions, ion, atom\n",
      "\n",
      "Cluster 19:\n",
      "theory, energy, functions, method, density, relativistic, states, matrix, electron, function, calculations, wave, body, functional, potential, equation, systems, results, coulomb, non\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most important chunks. See http://scikit-learn.org/stable/auto_examples/text/document_clustering.html\n",
    "order_centroids = clf_unsupervised.named_steps['clf'].cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "terms =  clf_unsupervised.named_steps['vect'].get_feature_names()\n",
    "for i in range(n_clusters):\n",
    "    print \"Cluster %d:\" % (i)\n",
    "    print ', '.join([terms[x] for x in order_centroids[i, :15]])\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
