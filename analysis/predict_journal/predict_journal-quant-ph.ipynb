{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use fancy machine learning to predict whether an article makes it into Nature/Science or PRL. This time we'll only look at articles in the physics.atom-ph section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Need to add parent directoy to sys.path to find 'metadataDB'\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Natural language processing toolkit\n",
    "# To use this, run nltk.download() and download 'stopwords'\n",
    "from nltk.corpus import stopwords\n",
    "s=stopwords.words('english') + ['']\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "# SQL\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from metadataDB.declareDatabase import *\n",
    "from sqlalchemy import or_, and_\n",
    "\n",
    "engine = create_engine(\"sqlite:///../arXiv_metadata.db\", echo=False)\n",
    "Base.metadata.bind = engine\n",
    "DBsession = sessionmaker(bind=engine)\n",
    "session = DBsession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = session.query(Article_Category)\\\n",
    "                    .join(Category)\\\n",
    "                    .join(Article)\\\n",
    "                    .filter(Category.name.like('%quant-ph'),\n",
    "                            or_(Article.journal_ref.like('Physics Review Letters%'),\n",
    "                                Article.journal_ref.like('Phys. Rev. Lett.%'),\n",
    "                                Article.journal_ref.like('PRL%')))\n",
    "abstractPRL = [x.article.abstract for x in query.all()]\n",
    "titlePRL = [x.article.title for x in query.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = session.query(Article_Category)\\\n",
    "                    .join(Category)\\\n",
    "                    .join(Article)\\\n",
    "                    .filter(Category.name.like('%quant-ph'),\n",
    "                            or_(Article.journal_ref.like('Nature%'),\n",
    "                                Article.journal_ref.like('Nat.%'),\n",
    "                                Article.journal_ref.like('Science%')))\n",
    "abstractNatureScience = [x.article.abstract for x in query.all()]\n",
    "titleNatureScience = [x.article.title for x in query.all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Train with 80% of the data, test with 20%\n",
    "# # First start with abstracts.\n",
    "\n",
    "# indPRL = len(abstractPRL)*4/5\n",
    "# indNatureScience = len(abstractNatureScience)*4/5\n",
    "\n",
    "# train_abstract = abstractPRL[:indPRL] + abstractNatureScience[:indNatureScience]\n",
    "# train_title = titlePRL[:indPRL] + titleNatureScience[:indNatureScience]\n",
    "# train_target = [0]*indPRL + [1]*indNatureScience\n",
    "# train_target_names = ['PRL']*indPRL + ['Nature']*indNatureScience\n",
    "\n",
    "# test_abstract = abstractPRL[indPRL:] + abstractNatureScience[indNatureScience:]\n",
    "# test_title = titlePRL[indPRL:] + titleNatureScience[indNatureScience:]\n",
    "# test_target = [0]*len(abstractPRL[indPRL:]) + [1]*len(abstractNatureScience[indNatureScience:])\n",
    "# test_target_names = ['PRL', 'Nature/Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train with 80% of the Nature data, test with 20% of the Nature data\n",
    "# Choose the same number of PRL and Nature articles in the test sets.\n",
    "\n",
    "indNatureScience = len(abstractNatureScience)*4/5\n",
    "indPRL = len(abstractPRL) - (len(abstractNatureScience) - indNatureScience)\n",
    "\n",
    "train_abstract = abstractPRL[:indPRL] + abstractNatureScience[:indNatureScience]\n",
    "train_title = titlePRL[:indPRL] + titleNatureScience[:indNatureScience]\n",
    "train_target = [0]*indPRL + [1]*indNatureScience\n",
    "train_target_names = ['PRL']*indPRL + ['Nature']*indNatureScience\n",
    "\n",
    "test_abstract = abstractPRL[indPRL:] + abstractNatureScience[indNatureScience:]\n",
    "test_title = titlePRL[indPRL:] + titleNatureScience[indNatureScience:]\n",
    "test_target = [0]*len(abstractPRL[indPRL:]) + [1]*len(abstractNatureScience[indNatureScience:])\n",
    "test_target_names = ['PRL', 'Nature/Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n",
      "2844\n"
     ]
    }
   ],
   "source": [
    "print len(abstractNatureScience)\n",
    "print len(abstractPRL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#SVC(kernel='linear') is good\n",
    "text_abstract_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,3))),\n",
    "                              ('tfidf', TfidfTransformer()),\n",
    "                              ('clf', SVC(kernel='linear'))])\n",
    "text_abstract_clf.fit(train_abstract, train_target)\n",
    "predict_abstract = text_abstract_clf.predict(test_abstract)\n",
    "print text_abstract_clf.predict(train_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_title_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "                              ('tfidf', TfidfTransformer()),\n",
    "                              ('clf', LinearSVC())])\n",
    "text_title_clf.fit(train_title, train_target)\n",
    "predict_title = text_title_clf.predict(test_title)\n",
    "print text_abstract_clf.predict(train_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
      " 1 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0\n",
      " 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print predict_abstract\n",
    "print predict_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           PRL       0.70      0.88      0.78       139\n",
      "Nature/Science       0.83      0.62      0.71       139\n",
      "\n",
      "   avg / total       0.77      0.75      0.74       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVC(kernel='linear')\n",
    "print(metrics.classification_report(test_target, predict_abstract,\n",
    "                                    target_names=test_target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           PRL       0.53      0.97      0.69       139\n",
      "Nature/Science       0.84      0.15      0.26       139\n",
      "\n",
      "   avg / total       0.69      0.56      0.47       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVC(kernel='linear')\n",
    "print(metrics.classification_report(test_target, predict_title,\n",
    "                                    target_names=test_target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 indicators of PRL:\n",
      "we propose, of the, propose, show, we, squeezing, method, show that, we show that, we show, resonance, scheme, rydberg, frequency, the spin, present, case, quantum light, discuss, consider, we study, entanglement entropy, we present, method for, prove, chain, generalized, chains, that the, shift, show that the, pm, ensemble, relations, between the, from the, macroscopic quantum, quantum dot, terms of, derive, analyze, in terms, in terms of, hidden, hand, cold, scheme for, phys, presence of, collective\n",
      "\n",
      "Top 50 indicators of Nature/Science:\n",
      "quantum, here, here we, and, of, to, been, have, here we demonstrate, in, these, has, information, photonic, fundamental, by, physics, here we report, systems, or, towards, as, however, circuits, demonstrate, integrated, devices, challenge, physical, new, communication, matter, technologies, many, single, demonstrated, we demonstrate, such, the, science, for, sensitivity, scalable, atoms, have been, annealing, at, mechanical, photon, optical\n"
     ]
    }
   ],
   "source": [
    "def inverseVectorizer(val):\n",
    "    return (key for key, value in text_abstract_clf.named_steps['vect'].vocabulary_.iteritems() if value == val).next()\n",
    "\n",
    "# This is super inefficient!!!\n",
    "sorted_coefs = sorted( ((i,v) for i, v in np.ndenumerate(text_abstract_clf.named_steps['clf'].coef_.todense()) ),\n",
    "                      key=lambda x: x[1] )\n",
    "\n",
    "print \"Top 50 indicators of PRL:\"\n",
    "bottom = sorted_coefs[:50]\n",
    "print \", \".join([ inverseVectorizer(item[0][1]) for item in bottom])\n",
    "print \"\"\n",
    "print \"Top 50 indicators of Nature/Science:\"\n",
    "top = list(reversed(sorted_coefs[-50:]))\n",
    "print \", \".join([ inverseVectorizer(item[0][1]) for item in top])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "  To build a fault-tolerant quantum computer, it is necessary to implement a\n",
      "quantum error correcting code. Such codes rely on the ability to extract\n",
      "information about the quantum error syndrome while not destroying the quantum\n",
      "information encoded in the system. Stabilizer codes are attractive solutions to\n",
      "this problem, as they are analogous to classical linear codes, have simple and\n",
      "easily computed encoding networks, and allow efficient syndrome extraction. In\n",
      "these codes, syndrome extraction is performed via multi-qubit stabilizer\n",
      "measurements, which are bit and phase parity checks up to local operations.\n",
      "Previously, stabilizer codes have been realized in nuclei, trapped-ions, and\n",
      "superconducting qubits. However these implementations lack the ability to\n",
      "perform fault-tolerant syndrome extraction which continues to be a challenge\n",
      "for all physical quantum computing systems. Here we experimentally demonstrate\n",
      "a key step towards this problem by using a two-by-two lattice of\n",
      "superconducting qubits to perform syndrome extraction and arbitrary error\n",
      "detection via simultaneous quantum non-demolition stabilizer measurements. This\n",
      "lattice represents a primitive tile for the surface code, which is a promising\n",
      "stabilizer code for scalable quantum computing. Furthermore, we successfully\n",
      "show the preservation of an entangled state in the presence of an arbitrary\n",
      "applied error through high-fidelity syndrome measurement. Our results bolster\n",
      "the promise of employing lattices of superconducting qubits for larger-scale\n",
      "fault-tolerant quantum computing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print text_abstract_clf.predict([test_abstract[-4]])\n",
    "print test_abstract[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
